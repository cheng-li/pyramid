########## IO ###########
#where to save model; always change this to avoid conflicts
output.folder=/tmp/out
# the name of the train folder
output.trainFolder=train
# the name of the test folder
output.testFolder=test
# the full name of the log file
# if not given, the log will be printed to the console
output.log=

######### functions ##########
# use two queries to specify training set and test set
# the query string should be the string after the top level "query":
# For example, if the curl command is
# curl -XGET "http://localhost:9200/ohsumed_20000/document/_search" -d'{"query":{"filtered":{"query":{"match_all":{}},"filter":{"term":{"split":"train"}}}}}'
# then the query string should be {"filtered":{"query":{"match_all":{}},"filter":{"term":{"split":"train"}}}}
# make sure the curly braces match

# the elasticsearch query string for matching training documents
train.splitQuery={"bool": {"must": {"match_all": {}},"filter": {"term": {"split": "train"}}}}
# the elasticsearch query string for matching test documents
test.splitQuery={"bool": {"must": {"match_all": {}},"filter": {"term": {"split": "test"}}}}


createTrainSet=true
createTestSet=true


########## index ########## 
index.indexName=ohsumed_20000
index.clusterName=fijielasticsearch
index.documentType=document
# node or transport
index.clientType=node
index.hosts=fiji11,fiji12
index.ports=9300,9300

######### feature ########## 
train.feature.useInitialFeatures=false
train.feature.featureFieldPrefix=feature
train.feature.categFeature.filter=false
train.feature.categFeature.percentThreshold=0.1
train.feature.ngram.n=1,2
train.feature.ngram.minDf=10
train.feature.ngram.slop=0,1
train.feature.ngram.extractionFields=body
# can be es_original, frequency, binary, tfifl
# tfifl = term frequency normalized by field length;
# to use tfifl, users should manually store the field length in a separate field named <field_name>_field_length, e.g., body_field_length
train.feature.ngram.matchScoreType=es_original

# whether to perform feature selection for ngrams
train.feature.ngram.selection=false
# if selection=true, how many ngrams to keep for each label
train.feature.ngram.selectPerLabel=50


train.feature.missingValue=false

# whether to add external ngrams from a file
# if true, user specified ngrams will be added to the feature matrix
train.feature.addExternalNgrams=false
# the file containing user specified ngrams, one ngram per line
# users do not need to manually analyze (tokenize, stem, filter) these ngrams, but need to specify the right analyzer below
train.feature.externalNgramFile=/home/chengli/experiments/pyramid/application/app3/configs/ohsumed_20000/ngramlist

# whether to filter ngram candidates based on a list of unigram keywords 
# if true, only ngrams (n>1) containing at least one of the keywords will be kept
train.feature.filterNgramsByKeyWords=false
# the file containing unigram keywords, one unigram per line
# users do not need to manually analyze (tokenize, stem, filter) these unigrams, but need to specify the right analyzer below
train.feature.filterNgrams.keyWordsFile=/home/chengli/experiments/pyramid/application/app3/configs/ohsumed_20000/keywords

# the program will use this analyzer to analyze (tokenize, stem, filter) the user provided ngrams and unigram keywords
# this analyzer should be the same as the one specified in the Elasticsearch body field mapping
train.feature.analyzer=english

# whether to filter ngram candidates by a regular expression
# if true, ngrams matching the regular expression will be removed
train.feature.filterNgramsByRegex=false

# the regular expression used to filter ngrams
# for example, \\d will remove a unigram if it is a digit
# users can specify ngram length in the regular expression using the number of spaces (an ngram has n-1 spaces)
# to help users understand and test the regular expression matching function, pyramid provides another application called "regex"
# users are encouraged to test their regular expression first with "regex"
train.feature.filterNgrams.regex=\\d

# whether to consider code description as features
train.feature.useCodeDescription=false
# the file containing code descriptions, each line in the file describes one code
train.feature.codeDesc.File=
# the program will use this analyzer to analyze (tokenize, stem, filter) the code descriptions
# this analyzer should be the same as the one specified in the Elasticsearch body field mapping
train.feature.codeDesc.analyzer=english
# which field we should match code descriptions against to compute matching scores
train.feature.codeDesc.matchField=body
# As most of the documents would match at least one word in the code description, direct partial matching results in dense features.
# We provide a threshold specifying the minimum percentage of the words in the code description the document must match. 
# Matching below the threshold will be discarded. 
# For example, if the description has 10 terms and a document matches 2 terms and minMatchPercentage=30, the matching score will be set to 0.
# The implementation uses minimum should match query + constance score
# see https://www.elastic.co/guide/en/elasticsearch/guide/current/ignoring-tfidf.html
# Matching k out of n words will gives a score of k^2/n^1.5 
# For boosting classifiers, we can simply interpret the score as k as monotonic transformations do no matter
train.feature.codeDesc.minMatchPercentage=20


######## labels #########
train.label.field=codes
train.label.filter=false
train.label.filter.prefix=foo
# encode labels in frequency or alphabetical order
train.label.order=frequency


# the internal Java class name for this application. 
# users do not need to modify this.
pyramid.class=App1

