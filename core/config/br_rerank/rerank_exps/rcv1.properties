
# The path to the input dataset; Please set the path properly on your computer
# There are 4 folders under that path: train, valid, cal, test 
# train is used for BR training; valid is used for hyper parameter tuning
# cal is used for calibrator training; test is used for evaluation
dataPath=/Users/chengli/tmp/br_rerank_release/sample_datasets/rcv1

# The directory for saving the program output
# Please set the outputDir properly on your computer
outputDir=/Users/chengli/tmp/br_rerank_release/outputs/rcv1


########## step 1: train BR #######################
# train the BR model
# After this step, the BR model named "model" will be saved to the "models" directory,
# and the BR model is applied to each dataset to generate "uncalibrated_label_confidence.txt" in the dataset report directory.
trainBR=true

#--- hyper parameters for BR training ---#
# logistic regression with L1 and L2 regularizations is used as BR's base learner
# number of BR training iterations
BR.iteration=5
# the regularization penalty for BR
BR.penalty=1E-6
# the l1 penalty Ratio
BR.l1Ratio=0.1


########## step 2: train label calibrator #######################
# train label calibrator
# After this step, "label_calibrator" will be saved to the "models" directory, 
# and the label calibrator is applied to turn "uncalibrated_label_confidence.txt" into "calibrated_label_confidence.txt". 
trainLabelCalibrator=true

# How to calibrate individual label probabilities
# set labelCalibrator.type=isotonic to calibrate by isotonic regression
# set labelCalibrator.type=none to not calibrate (use identity calibrator)
labelCalibrator.type=isotonic


########## step 3: train set calibrator #######################
# train set calibrator
trainSetCalibrator=true

# How to calibrate label set probabilities
# set setCalibrator=GB to calibrate by gradient boosting
# set setCalibrator=isotonic to calibrate by isotonic regression
# set setCalibrator=cardinality_isotonic to calibrate by cardinality based isotonic regression
# set setCalibrator=none to not calibrate
setCalibrator.type=GB

#---- hyper parameters of GB calibrator ---#

# The GB calibrator training objective: MSE or KL
setCalibrator.trainingObjective=MSE

# top-K candidates for training the calibrator
setCalibrator.numTrainCandidates=10
# top-K candidates for reranking during BR-rerank prediction
setCalibrator.numPredictCandidates=10

# whether to consider the set prior probability as a feature
setCalibrator.setPrior=true
# whether to consider the BR probability as a feature
setCalibrator.brProb=true
# whether to consider cardinality as a feature
setCalibrator.card=true
# whether to consider the the binary encoding the the predicted set as features
setCalibrator.encodeLabel=true

# number of leaves in GB regression tree weak learners
setCalibrator.numLeaves=10
# shinkage (learning rate) for GB training
setCalibrator.shrinkage=0.1
# minimum number of data points in each tree leaf node
setCalibrator.minDataPerLeaf=5
# maximum GB training iterations
# in practice, training may stop before it reaches the maximum iterations due to early stopping
setCalibrator.maxIteration=1000


########## step 4: make predictions #######################
# generate final set predictions and evaluation reports on test set
predict=true

# How you want to make predictions
# set predictMode=independent to get standard BR predictions
# set predictMode=rerank to get BR-rerank predictions
# Note that when comparing different calibrators' calibration performance, we need to fix the prediction method.
# Changing the prediction method and the calibration method at the same time will make the calibration results incomparable.
# For example, we could stick with the independent prediction method and compare the isotonic regression calibrator and GB calibrator.
predict.Mode=rerank


# the internal Java class name for this application.
# users do not need to modify this.
pyramid.class=BRRerank
