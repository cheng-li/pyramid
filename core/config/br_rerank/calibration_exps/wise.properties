
# The path to the input dataset; Please set the path properly on your computer
# There are 4 folders under that path: train, valid, cal, test 
# train is used for BR training; valid is used for hyper parameter tuning
# cal is used for calibrator training; test is used for evaluation
dataPath=/Users/chengli/tmp/br_rerank_release/sample_datasets/wise

# The directory for saving the program output
# Please set the outputDir properly on your computer
outputDir=/Users/chengli/tmp/br_rerank_release/outputs/wise

# whether to train the BR model
# please trainBR=true when running the program for the first time. The BR model will be trained and saved to the outputDir. 
# After that, you can set trainBR=false and re-use saved model
trainBR=true


# How you want to make predictions
# set predictMode=independent to get standard BR predictions
# set predictMode=rerank to get BR-rerank predictions
# Note that when comparing different calibrators' calibration performance, we need to fix the prediction method.
# Changing the prediction method and the calibration method at the same time will make the calibration results uncomparable.
# For example, we could stick with the independent prediction method and compare the isotonic regression calibrator and GB calibrator.
predictMode=independent

# How to calibrate individual label probabilities
# set labelCalibrator=isotonic to calibrate by isotonic regression
# set labelCalibrator=none to not calibrate
labelCalibrator=isotonic

# How to calibrate label set probabilities
# set setCalibrator=GB to calibrate by gradietn boosting
# set setCalibrator=isotonic to calibrate by isotonic regression
# set setCalibrator=cardinality_isotonic to calibrate by cardinality based isotonic regression
# set setCalibrator=none to not calibrate
setCalibrator=GB
# maximum GB training iterations

########## hyper parameters of GB calibrator #########

# The GB calibrator training objective: MSE or KL
trainingObjective=MSE

# top-K candidates for training the calibrator
numTrainCandidates=1
# top-K candidates for reranking during BR-rerank prediction
numPredictCandidates=1

# whether to consider the set prior probabiliy as a feature
setPrior=true
# whether to consider the BR probability as a feature
brProb=true
# whether to consider cardinality as a feature
card=true
# whether to consider the the binary encoding the the predicted set as features
encodeLabel=true

# number of leaves in GB regression tree weak learners
numLeaves=10
# shinkage (learning rate) for GB training
shrinkage=0.1
# minimum number of data points in each tree leaf node
minDataPerLeaf=5
# maximum GB training iterations
# in practce, training may stop before it reaches the maximum iterations due to early stopping
maxIteration=1000

########## hyper parameters for BR training #########
# logistic regression with L1 and L2 regularizations is used as BR's base learner
# number of BR training iterations
BR.iteration=2
# the regulariztion penalty for BR
BR.penalty=1E-6
# the l1 penalty Ratio
BR.l1Ratio=0.5


# the internal Java class name for this application.
# users do not need to modify this.
pyramid.class=BRRerank
